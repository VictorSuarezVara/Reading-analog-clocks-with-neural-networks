{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[BEST] - BaseLineModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxZql9aWxNIc"
      },
      "source": [
        "**BASELINE MODEL**\n",
        "=============================\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9mP_-wm6X6H"
      },
      "source": [
        "# ***INICIALITZATION***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10QiAmpWxg6M"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch, torchvision\n",
        "from torch import nn, optim\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_H_aQGYysoV",
        "outputId": "624dad7f-f58c-4676-fcb4-c362d50a5814"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CPU\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w4i7RVuy0b9"
      },
      "source": [
        "# Hyperparameters\n",
        "input_model_size=100\n",
        "in_channel = 1\n",
        "input_size = input_model_size*input_model_size*in_channel\n",
        "batch_size = 256\n",
        "\n",
        "dataSet_size = 50000\n",
        "train_percentage = 0.8\n",
        "test_percentage = 0.2\n",
        "\n",
        "m_learning_rate = 1e-2\n",
        "m_momentum=0.9\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "train_size = m = int(dataSet_size * train_percentage)\n",
        "test_size = int(dataSet_size * test_percentage)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQ0ZPqdNDRA"
      },
      "source": [
        "#HIPERPARAMETERS STANDARS\n",
        "num_classes_h = 12\n",
        "num_classes_m = 1  \n",
        "\n",
        "mean_calculated = 0.4888\n",
        "std_calculated = 0.2603\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWK50yyxzGfe"
      },
      "source": [
        "# ***LOAD DATASET***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi8PDVMEzQaI",
        "outputId": "776bde0f-fd38-4605-c5b1-330bbaba0226"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEqQidz-zRwO",
        "outputId": "aa150e95-a3d4-469e-b0f7-11dcab3e0750"
      },
      "source": [
        "#Extract data from the zip\n",
        "from zipfile import ZipFile\n",
        "root_datset = \"/content/drive/MyDrive/TFG/DataSets/Dtaset proto1/Archive/analog_clocks/images.zip\"\n",
        "with ZipFile(root_datset, 'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bh558jizl1N"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        ")  \n",
        "\n",
        "class Clocks(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=True):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, str(index)+'.jpg')\n",
        "        image = io.imread(img_path)\n",
        "\n",
        "        y_label1 = int(self.annotations.iloc[index, 0])\n",
        "        y_label2 = int(self.annotations.iloc[index, 1])/60\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            #image = image.view(image.size(1), image.size(2))\n",
        "            image = nn.functional.interpolate(image, size=input_model_size)\n",
        "            #print(\"Image size is\", image.size())\n",
        "            #print(image)\n",
        "            #sys.exit()\n",
        "        return (image, y_label1, y_label2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7zmuQJ8zIWe"
      },
      "source": [
        "# Load Data\n",
        "dataset = Clocks(\n",
        "    csv_file=\"/content/drive/MyDrive/TFG/DataSets/Dtaset proto1/Archive/analog_clocks/label.csv\",\n",
        "    root_dir=\"/content/images\",\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(mean_calculated, mean_calculated, mean_calculated), std=(std_calculated, std_calculated, std_calculated)),\n",
        "        transforms. Grayscale ( num_output_channels=1 )\n",
        "    ]),\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y6XKaLSxkD-"
      },
      "source": [
        "# ***MODEL TIME***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzfQEUiTgffY"
      },
      "source": [
        "**NN Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uROmnJvQf9cg"
      },
      "source": [
        "class basicCNN(nn.Module):\n",
        "    def __init__(self, num_ftrs, num_classes_h=12, num_classes_m=60):\n",
        "        super(basicCNN, self).__init__()\n",
        "        \n",
        "        #TRY with bias == 0\n",
        "        self.conv1 = nn.Conv2d(1, 50, kernel_size=(5, 5), stride=2, bias=True)\n",
        "        self.maxPool1 = nn.MaxPool2d((2, 2), stride=2)\n",
        "        self.batchNorm1 = nn.BatchNorm2d(50, affine=False)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(50, 100, kernel_size=(3, 3), stride=1, bias=True)\n",
        "        self.maxPool2 = nn.MaxPool2d((2, 2))\n",
        "        self.batchNorm2 = nn.BatchNorm2d(100, affine=False)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(100, 150, kernel_size=(3, 3), stride=1, bias=True)\n",
        "        self.maxPool3 = nn.MaxPool2d((2, 2))\n",
        "        self.batchNorm3 = nn.BatchNorm2d(150, affine=False)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(150, 200, kernel_size=(3, 3), stride=1, bias=True)\n",
        "        self.dropout4 = nn.Dropout(0.4)\n",
        "        \n",
        "        self.linearh1 = nn.Linear(in_features=200 * 15 * 2, out_features=144)\n",
        "        self.linearh2 = nn.Linear(in_features=144, out_features=144)\n",
        "        self.linearh3 = nn.Linear(in_features=144, out_features=num_classes_h)\n",
        "        \n",
        "        self.linearm1 = nn.Linear(in_features=200 * 15 * 2, out_features=200, bias=True)\n",
        "        self.linearm2 = nn.Linear(in_features=200, out_features=200, bias=True)\n",
        "        self.linearm3 = nn.Linear(in_features=200, out_features=100, bias=True)\n",
        "        self.linearm4 = nn.Linear(in_features=100, out_features=num_classes_m)\n",
        "        \n",
        "        self.activationConvsLayer = nn.ReLU(inplace=True)\n",
        "        self.activationFullyLayerHour = nn.ReLU(inplace=True)\n",
        "        self.activationFullyLayerMinute = nn.ReLU(inplace=True)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activationConvsLayer(x)\n",
        "        x = self.maxPool1(x)\n",
        "        x = self.batchNorm1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.activationConvsLayer(x)\n",
        "        x = self.maxPool2(x)\n",
        "        x = self.batchNorm2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.activationConvsLayer(x)\n",
        "        x = self.maxPool3(x)\n",
        "        x = self.batchNorm3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.activationConvsLayer(x)\n",
        "        x = self.dropout4(x)\n",
        "        #print(x.size())\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        hour = self.linearh1(x)\n",
        "        hour = self.activationFullyLayerHour(hour)\n",
        "        \n",
        "        hour = self.linearh2(hour)\n",
        "        hour = self.activationFullyLayerHour(hour)\n",
        "        \n",
        "        hour = self.linearh3(hour)\n",
        "\n",
        "\n",
        "        minute = self.linearm1(x)\n",
        "        minute = self.activationFullyLayerMinute(minute)\n",
        "        \n",
        "        minute = self.linearm2(minute)\n",
        "        minute = self.activationFullyLayerMinute(minute)\n",
        "        \n",
        "        minute = self.linearm3(minute)\n",
        "        minute = self.activationFullyLayerMinute(minute)\n",
        "        \n",
        "        minute = self.linearm4(minute)\n",
        "        minute = minute.view(-1)\n",
        "\n",
        "        return hour, minute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkzDB4FipCBI"
      },
      "source": [
        "**CHECK ACURACY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AiaHKt5n4pw"
      },
      "source": [
        "def check_accuracy(loader, model, type_of_data):\n",
        "    \n",
        "    print(\"Metrics of \", type_of_data, \" :\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    num_correct_h = 0\n",
        "    num_samples_h = 0\n",
        "\n",
        "    num_correct_m = 0\n",
        "    num_samples_m = 0\n",
        "\n",
        "    running_mae = 0\n",
        "    runnning_mse = 0\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, targeth, targetm in loader:\n",
        "            data = data.to(device=device)\n",
        "            targeth = targeth.to(device=device)\n",
        "            targetm = targetm.to(device=device)\n",
        "\n",
        "            scores_h, scores_m = model(data)\n",
        "            _, predictions_h = scores_h.max(1)\n",
        "            \n",
        "            num_correct_h += (predictions_h == targeth).sum()\n",
        "            num_samples_h += predictions_h.size(0)\n",
        "            \n",
        "            error = torch.abs(scores_m - targetm).sum().data\n",
        "            running_mae += error\n",
        "            \n",
        "            squared_error = ((scores_m - targetm)*(scores_m - targetm)).sum().data\n",
        "            runnning_mse += squared_error\n",
        "\n",
        "            num_samples_m += scores_m.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct_h} / {num_samples_h} for HOURS with accuracy {float(num_correct_h)/float(num_samples_h)*100:.2f}%\"          \n",
        "        )\n",
        "        print(\n",
        "            f\"For MINUTES we have mae {running_mae/num_samples_m*100:.2f}%\"\n",
        "        )\n",
        "        print(\n",
        "            f\"For MINUTES we have mse {runnning_mse/num_samples_m*100:.2f}%\"\n",
        "        )\n",
        "\n",
        "    model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QLKoN5kD0kc"
      },
      "source": [
        "**LET'S TRAIN OUR NETWORKY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHMjwf3ydvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e67fc511-d10b-4434-d415-3e5a97a73e31"
      },
      "source": [
        "#Charge model:\n",
        "# Initialize the model for this run\n",
        "model = basicCNN(input_size, num_classes_h=num_classes_h, num_classes_m=num_classes_m )\n",
        "model=model.to(device=device)\n",
        "\n",
        "# Optimize only the classifier\n",
        "optimizer = optim.SGD(model.parameters(), lr=m_learning_rate, momentum=m_momentum)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=m_learning_rate)\n",
        "\n",
        "#Criterion\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "criterion2 = nn.MSELoss()\n",
        "\n",
        "\n",
        "#data, targeth, targetm = next(iter(train_loader))\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    tic = time.time()\n",
        "    toolbar_width = 40\n",
        "\n",
        "    # setup toolbar\n",
        "    sys.stdout.write(\"[%s]\" % (\" \" * toolbar_width))\n",
        "    sys.stdout.flush()\n",
        "    sys.stdout.write(\"\\b\" * (toolbar_width+1)) # return to start of line, after '['\n",
        "    for batch_idx, (data, targeth, targetm) in enumerate(train_loader):\n",
        "        \n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targeth = targeth.to(device=device)\n",
        "        targetm = targetm.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        out1, out2 = model(data)\n",
        "        # print(out2.size())\n",
        "        loss1 = criterion1(out1, targeth)\n",
        "        loss2 = criterion2(out2, targetm.float())\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update the bar\n",
        "        if batch_idx%20==0:\n",
        "            sys.stdout.write(\"-\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    sys.stdout.write(\"] - 100%\\n\") # this ends the progress bar\n",
        "\n",
        "    toc = time.time()\n",
        "\n",
        "    print(\"Esta epoch ha tardado: \" + str((toc-tic)/60) + \" minutos\")\n",
        "check_accuracy(train_loader, model, \"train\")\n",
        "check_accuracy(test_loader, model, \"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------] - 100%\n",
            "Esta epoch ha tardado: 2.0156686067581178 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0173168818155927 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.029897566636403 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.003063416481018 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.016110157966614 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0093503912289936 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.01650839249293 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0034816741943358 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0062061309814454 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0137452244758607 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0110365827878316 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 1.9996281425158182 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.017072828610738 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0109228054682413 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.002910335858663 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0004241426785785 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0050381580988565 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0087021708488466 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0050546209017437 minutos\n",
            "[                                        ]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b--------] - 100%\n",
            "Esta epoch ha tardado: 2.0040512363115948 minutos\n",
            "Metrics of  train  :\n",
            "Got 39673 / 40000 for HOURS with accuracy 99.18%\n",
            "For MINUTES we have mae 6.44%\n",
            "For MINUTES we have mse 0.90%\n",
            "Metrics of  test  :\n",
            "Got 9610 / 10000 for HOURS with accuracy 96.10%\n",
            "For MINUTES we have mae 7.26%\n",
            "For MINUTES we have mse 1.21%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZYopz0Izzpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6e793e-b791-4b42-ac7c-2cd257def6d7"
      },
      "source": [
        "print(\"FINISH\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISH\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}